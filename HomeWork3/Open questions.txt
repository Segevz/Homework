1.	In general, why do we expect feature scaling to have a positive effect on our kNN algorithm? Would we expect to have a positive effect of feature scaling in the context of decision tree algorithms?

Answer: We could expect feature scaling to have a positive effect on kNN algorithm, due to the fact that different features may have different range of possible values.
		in this case this large range feature will be classified with high correlation (high weight) to the class value even tough maybe he isn't. scaling the features will solve this problem for us.
		in the case of Decision tree scaling the data will reduce the ability to split the data effectively due to the limitations of the computer to represent long float numbers.
		
		
2.	In class we saw we can perform an edited kNN algorithm which used either backward or forward kNN to filter out instances.
Could we use this procedure for our dataset? If so explain how, if not explain why.

Answer: Yes, we could use this procedure to prune our dataset, although it will have the most effectiveness on large datasets (ours is relatively small).
		Both of them happen in the preprocessing state and will prune the dataset. For forward kNN we will start with an empty dataset and only add to our dataset the wrongly classified instances.
		For backward kNN we will start with the entire dataset and will remove all the instances that are correctly classified.